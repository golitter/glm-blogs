LoRA是低秩适应（Low-Rank Adaptation），是参考了适配器微调（Adapter Tuning）的方法进行了优化，避免了由于适配器存在的推理延迟问题。

LoRA属于部分参数微调的方法，相比于全参数微调训练更加高效。

预训练、全参数、部分参数对比：

| 阶段     | 是否冻结参数 | 训练参数范围       | 数据规模 | 目的         |
| -------- | ------------ | ------------------ | -------- | ------------ |
| 预训练   | 否           | 所有参数           | 巨大     | 通用能力     |
| 全参微调 | 否           | 所有参数           | 较小     | 任务适应     |
| 部分微调 | 是           | 少量新增或选定参数 | 较小     | 高效任务适应 |

全参量微调是在原始的预训练模型参数基础上进行微调，部分参数微调要**冻结原始参数**，之后微调部分参数和原始参数合并得到最终的模型。



## LoRA

LoRA微调不插入新网络层，而是对预训练模型中的关键权重矩阵（O、K、V等）引入**低秩分解扰动**。

![img](lora%E3%80%81qlora%E5%BE%AE%E8%B0%83.assets/v2-16cb3f570884a176cb9bd1259abdff07_1440w.jpg)

预训练权重矩阵叫为$W_0$，那么权重的更新量就是$\Delta W$，$\Delta W = B A$，其中$A$是降维矩阵（训练前采用随机高斯分布初始化），$B$是升维矩阵（训练前采用零初始化）。在实际训练中，不去训练$W_0$，而是训练$A$和$B$，参数规模通常为原模型的0.1%~1%。

> **降维矩阵$A$使用随机高斯分布初始化**：未来保持模型的表达能力，高斯分布的随机初始化可以帮助模型在训练初期快速学习到有效的特征表示，从而提高模型的性能。
>
> **升维矩阵$B$使用零矩阵初始化**：未来减少原始模型参数的影响。将$B$初始化为零矩阵，使得在训练初期，模型仍然保持原始预训练参数的输出，从而保证模型在微调初期的稳定性。

在推理时，将$W_0$和$\Delta W$合并，因此不改变原模型结构。而且存储时可以直接存储不同任务的低秩矩阵权重，部署成本也较低。

LoRA模型的前向传播对应的公式为：$h = W_0 x + \Delta W x = W_p x + B \times A x$。

> 对于适配器微调的模型，会在自注意模块（以及MLP模块）和残差连接之间插入适配器层。但是其本质是修改了原始的模型任务，每次部署都需要完整的模型信息。对于多任务需要维护多个模型。
>
> **现在大部分部分参数微调用的是LoRA还有其变体**，适配器微调很少。

LoRA微调的优势：

- 可以针对不同的下游任务构建小型LoRA模型
- 采用自适应优化器，不需要计算梯度或维护大多数参数的优化器
- 线性设计，在部署时可将训练矩阵与冻结权重合并，不存在推理延迟
- 可以与其他方法正交，进行组合



[硬件依赖（ *估算值*）]([LLaMA-Factory/README_zh.md at main · hiyouga/LLaMA-Factory (github.com)](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md?plain=1))

| 方法                            | 精度 | 7B    | 14B   | 30B   | 70B    | `x`B    |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         | 32   | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              | 16   | 60GB  | 120GB | 300GB | 600GB  | `8x`GB  |
| Freeze/LoRA/GaLore/APOLLO/BAdam | 16   | 16GB  | 32GB  | 64GB  | 160GB  | `2x`GB  |
| QLoRA                           | 8    | 10GB  | 20GB  | 40GB  | 80GB   | `x`GB   |
| QLoRA                           | 4    | 6GB   | 12GB  | 24GB  | 48GB   | `x/2`GB |
| QLoRA                           | 2    | 4GB   | 8GB   | 16GB  | 24GB   | `x/4`GB |



LoRA可以针对多个模型层来进行微调：

|                  | 权重矩阵                 | 具体的模型层                   |
| ---------------- | ------------------------ | ------------------------------ |
| **注意力机制层** | W_q,W_k,W_v,W_o          | q_proj，k_proj，v_proj，o_proj |
| **前馈网络层**   | W_{up},W_{down},W_{gate} | up_proj，down_proj，gate_proj  |
| 词嵌入层         | W_e                      | embed_tokens                   |
| 其他层           | -                        | lm_head                        |

在实际中通常只用到**注意力机制层**和**前馈网络层**，这些层是模型中参数较多且对任务适应性影响较大的部分。

**一般微调$W_q$、$W_v$就可以**。

`lora_dropout`、`bias`只影响正则化，防止模型训练过拟合，使用默认值即可。

如果用$\alpha$代替`lora_alpha`，和$r$组合作为LoRA公式的缩放系数：$scale = \frac {\alpha} {r}$
$$
h = W_0 x + scale \times \Delta W x = W_0 x + \frac {\alpha} {r} \times B A x
$$
在给低秩更新做数值缩放时和$r$组合构成的系数对微调的性能有影响。因此，**确认了$r$之后，根据需要设定一个$scale$，即可得到对于的$\alpha$（`lora_alpha`）。

$r=8$时效果跟$r=64$基本一致。

> lora文中意思：$r=8$学到的8个主方向几乎全部被$r=64$的前8-10个方向所涵盖。即，低秩LoRA微调学到的核心方向，基本上就是高秩LoRA微调的核心方向，即使高秩微调有多个学习方向，但是影响模型性能的基本就是前面的部分。



## QLoRA

QLoRA（Quantized LoRA）本质是LoRA的量化版本，节省资源，但是会掉模型性能。

对于LoRA来说：

- 参与训练的参数量较少，解空间较小，效果相比全量微调又差距
- 微调大模型成本仍然很高
- 采用int4/8量化，会引发精度损失，降低模型性能

QLoRA是针对上面问题给出的解决方法，涉及到下面几个：

- **4bit 分位量化**：QLoRA包含一种低精度存储数据类似（通常为4bit）和一种计算数据类型（通常为bf16）。在微调时，QLoRA权重张量需要将张量去量化为bf16，在16位计算精度下进行矩阵乘法运算。模型本身用4bit加载，训练时将数值反量化到bf16后训练。
- **双重量化**：对第一次量化后的那些常量再进行一次量化，减少存储空间。
- **分页优化器**：防止梯度检查点中出现的内存峰值OOM。

**QLoRA是在微调过程中进一步减少内存占用的技术。在反向传播中，QLoRA将预训练的权重从fp16量化为4bit降低训练的显存，并使用分页优化器来防止OOM的出现**。

在反向传播训练过程中从原来的fp16精度训练量化到4bit，量化方法采用NF（NormalFloat），NF是Quantile Quantization的优化变体。

> Quatile Quantization：对于4bit，把所有的数字从小到大排列，再分成16等分，最小的一块映射到量化的第一个数...。这样原始数据在量化后的数字上分布就是均匀的。
>
> 之前的方法：进行round的舍入，可能没有充分利用有些数位，可能大部分原始数值都被量化到同一个4bit数。

![img](lora%E3%80%81qlora%E5%BE%AE%E8%B0%83.assets/v2-92d30438524177648a6863dc6c2ef5b7_1440w.jpg)

![img](lora%E3%80%81qlora%E5%BE%AE%E8%B0%83.assets/v2-3234cdf26a46b6878c02c4f994fd9a24_1440w.jpg)



[重温LoRA的原理，对比LoRA和QLoRA - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/1966453001830000363)

[QLoRA（Quantized LoRA）详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/666234324)

[LoRA与QLoRA快速介绍 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/688993851)